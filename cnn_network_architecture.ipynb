{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from src.data import DataLoaderScratch\n",
    "from src.trainer import TrainerScratch\n",
    "from src.optimizers import SGDScratch\n",
    "from src.functions import conv2d, maxpool2d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]\n",
    ")\n",
    "mnist_trainset = datasets.MNIST(\n",
    "    root=\"./data\", train=True, download=True, transform=transform\n",
    ")\n",
    "mnist_testset = datasets.MNIST(\n",
    "    root=\"./data\", train=False, download=True, transform=transform\n",
    ")\n",
    "\n",
    "# Transform the training data\n",
    "X_train = mnist_trainset.data.float() / 255.0\n",
    "# Add single dimension for the input channel\n",
    "X_train = X_train.unsqueeze(1)\n",
    "y_train = mnist_trainset.targets\n",
    "\n",
    "# Transform the test data\n",
    "X_val = mnist_testset.data.float() / 255.0\n",
    "# Add single dimension for the input channel\n",
    "X_val = X_val.unsqueeze(1)\n",
    "y_val = mnist_testset.targets\n",
    "\n",
    "train_dataloader = DataLoaderScratch(X_train, y_train, batch_size=256, shuffle=True)\n",
    "val_dataloader = DataLoaderScratch(X_val, y_val, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Batch Iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    out = torch.maximum(x, torch.zeros(1))\n",
    "    return out\n",
    "\n",
    "def softmax(X):\n",
    "    X_exp = torch.exp(X)\n",
    "    X_softmax = X_exp / X_exp.sum(axis=1, keepdims=True)\n",
    "    return X_softmax\n",
    "\n",
    "def log_loss(y_pred, y):\n",
    "    y_one_hot = nn.functional.one_hot(y)\n",
    "    loss = -(y_one_hot * torch.log(y_pred)).sum(axis=1).mean()\n",
    "    return loss\n",
    "\n",
    "def calculate_same_padding(input_size, kernel_size, stride):\n",
    "    if input_size % stride == 0:\n",
    "        pad_total = max(kernel_size - stride, 0)\n",
    "    else:\n",
    "        pad_total = max(kernel_size - (input_size % stride), 0)\n",
    "    padding = pad_total // 2\n",
    "    return padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a batch\n",
    "batch_size = 128\n",
    "perm = torch.randperm(len(X_train))\n",
    "X_batch = X_train[perm][:batch_size]\n",
    "y_batch = y_train[perm][:batch_size]\n",
    "\n",
    "batch_size, in_channels, input_height, input_width = X_batch.shape\n",
    "\n",
    "filter_size = 3 # Filter size for all layers\n",
    "pool_size = 2 # Pool size for all layers\n",
    "\n",
    "# CONV + POOL Layer 1\n",
    "out_channels1 = 16 # Number of filters in the first conv layer\n",
    "W1 = nn.Parameter(torch.randn(out_channels1, in_channels, filter_size, filter_size) * 0.01)\n",
    "b1 =  nn.Parameter(torch.zeros(size=(1, out_channels1, 1, 1)))\n",
    "# After Conv1 + Same Padding + Stride 1 => Shape remains [batch_size, out_channels1, input_height, input_width]\n",
    "# After Pooling1 with pool_size 2 and stride 2 => Shape: [batch_size, out_channels1, input_height/2, input_width/2]\n",
    "\n",
    "# CONV + POOL Layer 2\n",
    "out_channels2 = 32 # Number of filters in the second conv layer\n",
    "W2 = nn.Parameter(torch.randn(out_channels2, out_channels1, filter_size, filter_size) * 0.01)\n",
    "b2 = nn.Parameter(torch.zeros(size=(1, out_channels2, 1, 1)))\n",
    "# After Conv2 + Same Padding + Stride 1 => Shape: [batch_size, out_channels2, input_height/2, input_width/2]\n",
    "# After Pooling2 with pool_size 2 and stride 2 => Shape: [batch_size, out_channels2, input_height/4, input_width/4]\n",
    "\n",
    "# FC Layer\n",
    "# Before the FC layer, the output from the last pooling layer is flattened\n",
    "# Flattened shape: [batch_size, out_channels2 * (input_height/4) * (input_width/4)]\n",
    "num_classes = 10  # For example, in a classification problem with 10 classes\n",
    "# Initialize the fc layer weights\n",
    "W3 = nn.Parameter(torch.randn(out_channels2 * int(input_height/4 * input_height/4), num_classes) * 0.01)\n",
    "b3 = nn.Parameter(torch.zeros(num_classes))\n",
    "# The FC layer maps from the flattened size to the number of classes\n",
    "# After FC => Shape: [batch_size, num_classes]\n",
    "\n",
    "parameters = [W1, b1, W2, b2, W3, b3]\n",
    "optimizer = SGDScratch(parameters, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero gradients\n",
    "optimizer.zero_grad()\n",
    "\n",
    "# CONV + POOL Layer 1\n",
    "padding = calculate_same_padding(input_height, filter_size, 1)\n",
    "Z1 = conv2d(X_batch, W1, padding=padding) + b1\n",
    "A1 = relu(Z1)\n",
    "P1 = maxpool2d(A1, kernel_size=pool_size, stride=2)\n",
    "\n",
    "# CONV + POOL Layer 2\n",
    "padding = calculate_same_padding(P1.size(3), filter_size, 1)\n",
    "Z2 = conv2d(P1, W2, padding=padding) + b2\n",
    "A2 = relu(Z2)\n",
    "P2 = maxpool2d(A2, kernel_size=pool_size, stride=2)\n",
    "\n",
    "# FC Layer\n",
    "P2_flat = P2.flatten(start_dim=1)\n",
    "Z3 = P2_flat @ W3 + b3\n",
    "y_pred = softmax(Z3)\n",
    "\n",
    "# Calculate Loss\n",
    "loss = log_loss(y_pred, y_batch)\n",
    "\n",
    "# Compute gradients\n",
    "loss.backward()\n",
    "\n",
    "# Update parameters\n",
    "optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
