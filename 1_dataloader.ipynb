{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement a dataloader from scratch. The dataloader takes in a set of features X and targets y and transforms them into batches that can be iterated over. We also implement the option to shuffle the dataset before splitting it up in batches. And, we implement the len function to obtain the number of batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self, X, y, batch_size=64, shuffle=True):\n",
    "        \"\"\"\n",
    "        Custom DataLoader for batching and iterating over a dataset.\n",
    "\n",
    "        :param X: Input features, can be a list, numpy array, or PyTorch tensor.\n",
    "        :param y: Labels corresponding to input features.\n",
    "        :param batch_size: Number of samples per batch.\n",
    "        :param shuffle: Whether to shuffle the data at the beginning of each iteration.\n",
    "        :param transform: Optional transform to be applied on each batch.\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the number of batches in the DataLoader.\"\"\"\n",
    "        return int(np.ceil(len(self.X) / self.batch_size))\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Iterator to generate data batches.\"\"\"\n",
    "        n_samples = len(self.X)\n",
    "        indices = np.arange(n_samples)\n",
    "\n",
    "        if self.shuffle:\n",
    "            indices = np.random.permutation(indices)\n",
    "\n",
    "        for start_idx in range(0, n_samples, self.batch_size):\n",
    "            end_idx = min(start_idx + self.batch_size, n_samples)\n",
    "            batch_indices = indices[start_idx:end_idx]\n",
    "\n",
    "            X_batch = self.X[batch_indices]\n",
    "            y_batch = self.y[batch_indices]\n",
    "\n",
    "            yield X_batch, y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some data\n",
    "n_samples = 1000\n",
    "n_features = 5\n",
    "X_train = torch.randn(n_samples, n_features)\n",
    "true_weights = torch.randn(n_features, 1)\n",
    "y_train = X_train @ true_weights + torch.randn(n_samples, 1) * 0.5\n",
    "\n",
    "train_dataloader = DataLoader(X_train, y_train, batch_size=256, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 5]) torch.Size([256, 1])\n",
      "torch.Size([256, 5]) torch.Size([256, 1])\n",
      "torch.Size([256, 5]) torch.Size([256, 1])\n",
      "torch.Size([232, 5]) torch.Size([232, 1])\n"
     ]
    }
   ],
   "source": [
    "for X_batch, y_batch in train_dataloader:\n",
    "    print(X_batch.shape, y_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataloader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
